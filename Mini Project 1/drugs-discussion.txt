Every time we run the models, the training and testing sets are randomized. Because of this, when learning from a different set, the same model will give you different results. This is why every time the model was ran, different results happened. This is why we compiled averages of the important performance statistics. We note that the model with the highest average accuracy was the top decision tree, and the one with the lowest was the naive bayes model. The model with the highest average macro average was again the top decision tree, with the lowest one being the base multi-layered perceptron. The model with the highest average weighted average was again the top decision tree and the one with the lowest was the base multi-layered perceptron. One interesting thing to note is that the base model for the decision tree and for the multi-layered perceptron were both outperformed by their top models.
